---
title: Vercel AI SDK
description: Vercel AI SDK compatible SDK reference
---

# Vercel AI SDK

The [@gensx/vercel-ai](https://www.npmjs.com/package/@gensx/vercel-ai) package provides [Vercel AI SDK](https://sdk.vercel.ai/docs/introduction) compatible components for GenSX, allowing you to use Vercel's AI SDK with GenSX's component model.

## Installation

To install the package, run the following command:

```bash
npm install @gensx/vercel-ai
```

You'll also need to install the relevant providers from the Vercel AI SDK:

```bash
npm install @ai-sdk/openai
```

Then import the components you need from the package:

```ts
import { generateText, generateObject } from "@gensx/vercel-ai";
```

## Supported components

| <div style={{width: "150px"}}>Component</div> | Description                                                    |
| :-------------------------------------------- | :------------------------------------------------------------- |
| [`generateText`](#generatetext)               | Generate complete text responses from language models          |
| [`generateObject`](#generateobject)           | Generate complete structured JSON objects from language models |
| [`streamText`](#streamtext)                   | Stream text responses from language models                     |
| [`streamObject`](#streamobject)               | Stream structured JSON objects from language models            |
| [`embed`](#embed)                             | Generate embeddings for a single text input                    |
| [`embedMany`](#embedmany)                     | Generate embeddings for multiple text inputs                   |
| [`generateImage`](#generateimage)             | Generate images from text prompts                              |

## Component Reference

#### `generateText`

The [`generateText`](https://sdk.vercel.ai/docs/ai-sdk-core/generating-text#generatetext) component generates complete text responses from language models, waiting for the entire response before returning.

```ts
import { generateText } from "@gensx/vercel-ai";
import { openai } from "@ai-sdk/openai";

const result = await generateText({
  prompt: "Write a poem about a cat",
  model: openai("gpt-4.1-mini"),
});

console.log(result.text);
```

##### Props

The `generateText` component accepts all parameters from the Vercel AI SDK's `generateText` function:

- `prompt` (required): The text prompt to send to the model
- `model` (required): The language model to use (from Vercel AI SDK)
- Plus any other parameters supported by the Vercel AI SDK

##### Return Type

Returns a complete text string containing the model's response.

#### `generateObject`

The [`generateObject`](https://sdk.vercel.ai/docs/ai-sdk-core/generating-structured-data#generate-object) component generates complete structured JSON objects from language models, with type safety through Zod schemas.

```ts
import { generateObject } from "@gensx/vercel-ai";
import { openai } from "@ai-sdk/openai";
import { z } from "zod";

const userSchema = z.object({
  user: z.object({
    name: z.string(),
    age: z.number(),
    interests: z.array(z.string()),
    contact: z.object({
      email: z.string().email(),
      phone: z.string().optional(),
    }),
  }),
});

const result = await generateObject({
  prompt,
  schema: userSchema,
  model: openai("gpt-4.1-mini"),
});

console.log(result.object);
```

##### Props

The `generateObject` component accepts all parameters from the Vercel AI SDK's `generateObject` function:

- `prompt` (required): The text prompt to send to the model
- `model` (required): The language model to use (from Vercel AI SDK)
- `schema`: A Zod schema defining the structure of the response
- `output`: The output format ("object", "array", or "no-schema")
- Plus any other optional parameters supported by the Vercel AI SDK

##### Return Type

Returns a structured object matching the provided schema.

#### `streamText`

The [`streamText`](https://sdk.vercel.ai/docs/ai-sdk-core/generating-text#streamtext) component streams text responses from language models, making it ideal for chat interfaces and other applications where you want to show responses as they're generated.

```ts
import { streamText } from "@gensx/vercel-ai";
import { openai } from "@ai-sdk/openai";

const result = streamText({
  messages: [
    {
      role: "system",
      content: "You are a helpful assistant",
    },
    {
      role: "user",
      content: "write a children's book about AGI",
    },
  ],
  model: openai("gpt-4.1-mini"),
});

for await (const chunk of result.textStream) {
  console.log(chunk);
}
```

##### Props

The `streamText` component accepts all parameters from the Vercel AI SDK's `streamText` function:

- `prompt` (required): The text prompt to send to the model
- `model` (required): The language model to use (from Vercel AI SDK)
- Plus all other parameters supported by the Vercel AI SDK

##### Return Type

Returns a streaming response that can be consumed token by token.

#### `streamObject`

The [`streamObject`](https://sdk.vercel.ai/docs/ai-sdk-core/generating-structured-data#stream-object) component streams structured JSON objects from language models, allowing you to get structured data with type safety.

```ts
import { streamObject } from "@gensx/vercel-ai";
import { openai } from "@ai-sdk/openai";
import { z } from "zod";

// Define a schema for the response
const recipeSchema = z.object({
  recipe: z.object({
    name: z.string(),
    ingredients: z.array(z.string()),
    steps: z.array(z.string()),
  }),
});

const result = streamObject({
  prompt: "Generate a recipe for chocolate chip cookies",
  schema: recipeSchema,
  model: openai("gpt-4.1-mini"),
});

for await (const chunk of result.partialObjectStream) {
  console.log(chunk);
}
```

##### Props

The `streamObject` component accepts all parameters from the Vercel AI SDK's `streamObject` function:

- `prompt` (required): The text prompt to send to the model
- `model` (required): The language model to use (from Vercel AI SDK)
- `schema`: A Zod schema defining the structure of the response
- `output`: The output format ("object", "array", or "no-schema")
- Plus all other parameters supported by the Vercel AI SDK

##### Return Type

Returns a structured object matching the provided schema.

#### `embed`

The [`embed`](https://sdk.vercel.ai/docs/ai-sdk-core/embeddings) component generates embeddings for a single text input, which can be used for semantic search, clustering, and other NLP tasks.

```ts
import { embed } from "@gensx/vercel-ai";
import { openai } from "@ai-sdk/openai";
import * as gensx from "@gensx/core";

const result = await embed({
  value: "the cat jumped over the dog",
  model: openai.embedding("text-embedding-3-small");,
});

console.log(result.embedding)
```

##### Props

The `embed` component accepts all parameters from the Vercel AI SDK's `embed` function:

- `value` (required): The text to generate an embedding for
- `model` (required): The embedding model to use (from Vercel AI SDK)
- Plus any other optional parameters supported by the Vercel AI SDK

##### Return Type

Returns a vector representation (embedding) of the input text.

#### `embedMany`

The [`embedMany`](https://sdk.vercel.ai/docs/ai-sdk-core/embeddings#embedding-many-values) component generates embeddings for multiple text inputs in a single call, which is more efficient than making separate calls for each text.

```ts
import { embedMany } from "@gensx/vercel-ai";
import { openai } from "@ai-sdk/openai";

const texts = [
  "the cat jumped over the dog",
  "the dog chased the cat",
  "the cat ran away",
];

const result = await embedMany({
  values: texts,
  model: openai.embedding("text-embedding-3-small"),
});

console.log(result.embeddings);
```

##### Props

The `EmbedMany` component accepts all parameters from the Vercel AI SDK's `embedMany` function:

- `values` (required): Array of texts to generate embeddings for
- `model` (required): The embedding model to use (from Vercel AI SDK)
- Plus any other optional parameters supported by the Vercel AI SDK

##### Return Type

Returns an array of vector representations (embeddings) for the input texts.

#### `generateImage`

The [`generateImage`](https://sdk.vercel.ai/docs/ai-sdk-core/image-generation) component generates images from text prompts using image generation models.

```ts
import { generateImage } from "@gensx/vercel-ai";
import { openai } from "@ai-sdk/openai";

const result = await generateImage({
  prompt: "a bear walking through a lush forest",
  model: openai.image("dall-e-3"),
});

console.log(result);
```

##### Props

The `generateImage` component accepts all parameters from the Vercel AI SDK's `experimental_generateImage` function:

- `prompt` (required): The text description of the image to generate
- `model` (required): The image generation model to use (from Vercel AI SDK)
- Plus any other optional parameters supported by the Vercel AI SDK

##### Return Type

Returns an object containing information about the generated image, including its URL.

## Usage with Different Models

The Vercel AI SDK supports multiple model providers. Here's how to use different providers with GenSX components:

```ts
// OpenAI
import { openai } from "@ai-sdk/openai";
const openaiModel = openai("gpt-4.1");

// Anthropic
import { anthropic } from "@ai-sdk/anthropic";
const anthropicModel = anthropic("claude-sonnet-4-20250514");

// Gemini
import { google } from "@ai-sdk/google";
const googleModel = google("gemini-2.5-flash-preview-05-20");
```

For more information on the Vercel AI SDK, visit the [official documentation](https://sdk.vercel.ai/docs).
